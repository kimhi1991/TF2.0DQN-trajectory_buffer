general:
  completion_reward: 0.9
  cycles: 100000
  episodes_per_test: 100
  episodes_per_training_cycle: 10
  gamma: 0.99
  max_test_episode_steps: 200
  max_train_episode_steps: 200
  test_frequency: 100
model:
  batch_size: 32
  decrease_epsilon: 0.9999
  decrease_trajectory_ratio: 1
  epsilon: 1.0
  min_epsilon: 0.01
  min_trajectory_ratio: 0.5
  min_trajectory_ratio_2: 0.1
  replay_buffer_size: 10000
  train_steps_per_cycle: 200
  trajectory_ratio: 1
  trajectory_ratio_2: 0.0
policy_network:
  activation: relu
  layers:
  - 256
  - 512
  learn_rate: 0.001
  tau: 0.95
