general:
  completion_reward: 0.9
  cycles: 10000
  episodes_per_test: 100
  episodes_per_training_cycle: 10
  gamma: 0.99
  max_test_episode_steps: 200
  max_train_episode_steps: 200
  test_frequency: 100
model:
  batch_size: 1
  decrease_epsilon: 0.999
  epsilon: 1.0
  min_epsilon: 0.01
  replay_buffer_size: 1000
  train_steps_per_cycle: 100
policy_network:
  activation: relu
  layers:
  - 256
  - 512
  learn_rate: 0.01
  tau: 0.95
