general:
  completion_reward: 195.0
  cycles: 1000
  episodes_per_test: 100
  episodes_per_training_cycle: 4
  gamma: 0.99
  max_test_episode_steps: 10000
  max_train_episode_steps: 1000
  test_frequency: 100
model:
  batch_size: 32
  decrease_epsilon: 0.995
  epsilon: 0.8
  min_epsilon: 0.001
  replay_buffer_size: 1000
  train_steps_per_cycle: 5
  trajectory_ratio: 0
policy_network:
  activation: relu
  layers:
  - 20
  - 20
  - 20
  learn_rate: 0.001
  tau: 0.95
