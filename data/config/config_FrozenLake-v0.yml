general:
  cycles: 10000
  episodes_per_training_cycle: 10
  episodes_per_test: 100
  max_train_episode_steps: 200
  max_test_episode_steps: 200
  gamma: 0.99

  test_frequency: 100
  completion_reward: 0.9

model:
  trajectory_ratio: 1
  min_trajectory_ratio: 0.5

  trajectory_ratio_2: 0.5
  min_trajectory_ratio_2: 0.1

  decrease_trajectory_ratio: 0.99999

  replay_buffer_size: 1000
  epsilon: 1.
  min_epsilon: 0.01
  decrease_epsilon: 0.999
  batch_size: 32
  train_steps_per_cycle: 200

policy_network:
  learn_rate: 0.01 #0.001
  tau: 0.95
  layers: [256, 512]
  activation: 'relu'